---
layout: post
title: Apache_Kafka入门（一）
category: ['kafka']
tags: ['kafka', 'zookeeper']
author: 高晓波
email: gaoxb3@asiainfo.com
description: 简单介绍kafka基本概念，以及环境的搭建
---

# 一、kafka是什么？ 
>  kafka是一个分布式的、可分区的、可复制的消息系统。它使用Scala编写，它以可水平扩展和高吞吐率而被广泛使用。

# 二、产生背景

> Kafka是一个消息系统，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的3是服务器的性能数据（CPU、IO使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。

# 三、基本架构图
![kafka](/images/gaoxiaobo/kafka1.png)

# 四、基本概念的解释
1. **Broker**
Kafka集群包含一个或多个服务器，这种服务器被称为broker。broker端不维护数据的消费状态，提升了性能。直接使用磁盘进行存储，线性读写，速度快：避免了数据在JVM内存和系统内存之间的复制，减少耗性能的创建对象和垃圾回收。 

2. **Producer**
负责发布消息到Kafka broker

3. **Consumer**
 消息消费者，向Kafka broker读取消息的客户端，consumer从broker拉取(pull)数据并进行处理。

4. **Topic**
 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）

5. **Partition**
Parition是物理上的概念，每个Topic包含一个或多个Partition.

6. **Consumer Group**
每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）

# 五、kafka集群环境搭建

## 1) Zookeeper集群搭建
> Kafka集群是把状态保存在Zookeeper中的，首先要搭建Zookeeper集群。
Zookeeper环境的搭建请参照[《Storm(2)-Storm集群的搭建》](http://www.blogways.net/blog/2016/11/20/storm-2.html)。需要注意的是zookeeper需要java环境，所以记得先安装JDK。

## 2) Kafka集群搭建
* **软件环境**
	1、linux一台或多台，大于等于2
	2、已经搭建好的zookeeper集群
	3、软件版本kafka_2.11-0.9.0.1.tgz

* **创建目录并下载安装软件**

	```
	#下载软件
	cd /usr/local/src/
	wget  http://apache.opencas.org/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz

	#解压软件
	tar -zxvf kafka_2.11-0.9.0.1.tgz

	```	

*  **修改配置文件**

 进入config目录，我们可以发现在目录下有很多文件，这里可以发现有Zookeeper文件，我们可以根据Kafka内带的zk集群来启动，但是建议使用独立的zk集群。这里主要关注：server.properties 这个文件即可。

server.properties配置注解：

```
broker.id=0  #当前机器在集群中的唯一标识，和zookeeper的myid性质一样
port=19092 #当前kafka对外提供服务的端口默认是9092
host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。
num.network.threads=3 #这个是borker进行网络处理的线程数
num.io.threads=8 #这个是borker进行I/O处理的线程数
log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个
socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能
socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘
socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小
num.partitions=1 #默认的分区数，一个topic默认1个分区数
log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天
message.max.byte=5242880  #消息保存的最大值5M
default.replication.factor=2  #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
replica.fetch.max.bytes=5242880  #取消息的最大直接数
log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除
log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能
zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口
```

 实际的修改项为：
```
broker.id=0  #每台服务器的broker.id都不能相同
listeners=PLAINTEXT://192.168.43.40:9092
port=9092
在log.retention.hours=168 下面新增下面三项
message.max.byte=5242880
default.replication.factor=2
replica.fetch.max.bytes=5242880
设置zookeeper的连接端口
zookeeper.connect=192.168.43.40:2181,192.168.43.41:2181,192.168.43.42:2181
```

* **启动zookeeper、kafka集群并测试**
 启动服务：
```
##启动zookeeper
[root@host1 config]# cd /usr/local/src/zookeeper-3.4.6
[root@host1 zookeeper-3.4.6]# ./bin/zkServer.sh start ./conf/zoo.cfg
##启动kafka
[root@host1 zookeeper-3.4.6]# cd /usr/local/src/kafka_2.11-0.9.0.1
[root@host1 kafka_2.11-0.9.0.1]# ./bin/kafka-server-start.sh -daemon ./config/server.properties
```
 查看服务是否正常启动：
```
[root@host1 kafka_2.11-0.9.0.1]# jps
2356 QuorumPeerMain
2550 Jps
2413 Kafka
```

 创建Topic、Producer、Consumer测试:
```
#创建Topic
./kafka-topics.sh --create --zookeeper 192.168.43.40:2181 --replication-factor 2 --partitions 1 --topic test
#解释
--replication-factor 2   #复制两份
--partitions 1 #创建1个分区
--topic #主题为test
#在一台服务器上创建一个发布者
#创建一个broker，发布者
./kafka-console-producer.sh --broker-list 192.168.43.40:9092 --topic test
#在一台服务器上创建一个订阅者
./kafka-console-consumer.sh --zookeeper 192.168.43.40:2181 --topic test --from-beginning
```
测试（在发布者那里发布消息看看订阅者那里是否能正常收到~）
![kafka_sendMsg](/images/gaoxiaobo/kafka2.png)