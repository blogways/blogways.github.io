I"‹Y<h1 id="apache_kafkaå…¥é—¨äºŒ">Apache_Kafkaå…¥é—¨ï¼ˆäºŒï¼‰</h1>

<blockquote>
  <p>å‰é¢æˆ‘ä»¬æ­å»ºäº†3ä¸ªbrokerçš„kafkaé›†ç¾¤
æœ¬ç¯‡æˆ‘ä»¬ä»‹ç»ä¸€ä¸‹kafkaçš„ä¸€äº›é…ç½®ä»¥åŠjavaä»£ç ï¼Œä»ä¸­å­¦ä¹ å’Œç†è§£kafkaçš„ä¸€äº›è®¾è®¡ã€‚</p>
</blockquote>

<h2 id="ä¸€producerå’Œconsumerä¸»è¦é…ç½®">ä¸€ã€Producerå’ŒConsumerä¸»è¦é…ç½®</h2>
<p>æˆ‘ä»¬å…ˆæ¥å­¦ä¹ ä¸€ä¸‹kafkaå…³äºproducerå’Œconsumerçš„ä¸€äº›é…ç½®ï¼Œé€šè¿‡é…ç½®ä¿¡æ¯å¯¹producerå’Œconsumeræœ‰ä¸ªå¤§ä½“äº†è§£ï¼ŒåŒæ—¶ä¹Ÿæ˜¯åœ¨æ­¤åšä¸ªè®°å½•ï¼Œæ–¹ä¾¿æ—¥åä½¿ç”¨æ—¶æŸ¥é˜…ã€‚</p>

<ul>
  <li>Producerä¸»è¦é…ç½®ï¼š<a href="http://kafka.apache.org/documentation.html#producerconfigs">å®˜æ–¹æ–‡æ¡£</a></li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ç”¨äºå»ºç«‹ä¸kafkaé›†ç¾¤çš„è¿æ¥ï¼Œè¿™ä¸ªlistä»…ä»…å½±å“ç”¨äºåˆå§‹åŒ–çš„hostsï¼Œæ¥å‘ç°å…¨éƒ¨çš„serversã€‚
##æ ¼å¼ï¼šhost1:port1,host2:port2,â€¦ï¼Œæ•°é‡å°½é‡ä¸æ­¢ä¸€ä¸ªï¼Œä»¥é˜²å…¶ä¸­ä¸€ä¸ªdownäº†
bootstrap.servers=192.168.127.10:9092,192.168.127.11:9092,192.168.127.12:9092

# Producerç”¨äºå‹ç¼©æ•°æ®çš„å‹ç¼©ç±»å‹ï¼Œå–å€¼ï¼šnone, gzip, snappy, or lz4
compression.type=none

# æ¶ˆæ¯åºåˆ—åŒ–ç±»ï¼Œé»˜è®¤ä¸ºkafka.serializer.DefaultEncoderï¼Œå°†æ¶ˆæ¯å®ä½“è½¬åŒ–ä¸ºbyte[]
serializer.class=kafka.serializer.StringEncoder

# produceræ¥æ”¶æ¶ˆæ¯ackçš„æ—¶æœºï¼Œé»˜è®¤ä¸º0
# 0:producerä¸ä¼šç­‰å¾…ç¡®è®¤ï¼Œç›´æ¥æ·»åŠ åˆ°socketç­‰å¾…å‘é€ï¼›
# 1:è¿™æ„å‘³ç€è‡³å°‘è¦ç­‰å¾…leaderå·²ç»æˆåŠŸå°†æ•°æ®å†™å…¥æœ¬åœ°logï¼Œä½†æ˜¯å¹¶æ²¡æœ‰ç­‰å¾…æ‰€æœ‰followeræ˜¯å¦æˆåŠŸå†™å…¥ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœfolloweræ²¡æœ‰æˆåŠŸå¤‡ä»½æ•°æ®ï¼Œè€Œæ­¤æ—¶leaderåˆæŒ‚æ‰ï¼Œåˆ™æ¶ˆæ¯ä¼šä¸¢å¤±ã€‚
# all:è¿™æ„å‘³ç€leaderéœ€è¦ç­‰å¾…æ‰€æœ‰å¤‡ä»½éƒ½æˆåŠŸå†™å…¥æ—¥å¿—ï¼Œè¿™ç§ç­–ç•¥ä¼šä¿è¯åªè¦æœ‰ä¸€ä¸ªå¤‡ä»½å­˜æ´»å°±ä¸ä¼šä¸¢å¤±æ•°æ®ã€‚è¿™æ˜¯æœ€å¼ºçš„ä¿è¯ã€‚
acks=0

# Producerå¯ä»¥ç”¨æ¥ç¼“å­˜æ•°æ®çš„å†…å­˜å¤§å°ã€‚
##å¦‚æœæ•°æ®äº§ç”Ÿé€Ÿåº¦å¤§äºå‘brokerå‘é€çš„é€Ÿåº¦ï¼Œproducerä¼šé˜»å¡max.block.msï¼Œè¶…æ—¶åˆ™æŠ›å‡ºå¼‚å¸¸
buffer.memory=

# Produceré»˜è®¤ä¼šæŠŠä¸¤æ¬¡å‘é€æ—¶é—´é—´éš”å†…æ”¶é›†åˆ°çš„æ‰€æœ‰Requestsè¿›è¡Œä¸€æ¬¡èšåˆç„¶åå†å‘é€ï¼Œä»¥æ­¤æé«˜ååé‡ï¼Œè€Œlinger.msåˆ™æ›´è¿›ä¸€æ­¥ï¼Œè¿™ä¸ªå‚æ•°ä¸ºæ¯æ¬¡å‘é€å¢åŠ ä¸€äº›delayï¼Œä»¥æ­¤æ¥èšåˆæ›´å¤šçš„Messageã€‚
linger.ms=

# è¯·æ±‚çš„æœ€å¤§å­—èŠ‚æ•°ã€‚è¿™ä¹Ÿæ˜¯å¯¹æœ€å¤§æ¶ˆæ¯å¤§å°çš„æœ‰æ•ˆé™åˆ¶ã€‚
# æ³¨æ„ï¼šserverå…·æœ‰è‡ªå·±å¯¹æ¶ˆæ¯å¤§å°çš„é™åˆ¶ï¼Œè¿™äº›å¤§å°å’Œè¿™ä¸ªè®¾ç½®ä¸åŒã€‚æ­¤é¡¹è®¾ç½®å°†ä¼šé™åˆ¶produceræ¯æ¬¡æ‰¹é‡å‘é€è¯·æ±‚çš„æ•°ç›®ï¼Œä»¥é˜²å‘å‡ºå·¨é‡çš„è¯·æ±‚ã€‚
max.request.size=

# TCPçš„æ¥æ”¶ç¼“å­˜ SO_RCVBUF ç©ºé—´å¤§å°ï¼Œç”¨äºè¯»å–æ•°æ®
receive.buffer.bytes=

# clientç­‰å¾…è¯·æ±‚å“åº”çš„æœ€å¤§æ—¶é—´,å¦‚æœåœ¨è¿™ä¸ªæ—¶é—´å†…æ²¡æœ‰æ”¶åˆ°å“åº”ï¼Œå®¢æˆ·ç«¯å°†é‡å‘è¯·æ±‚ï¼Œè¶…è¿‡é‡è¯•æ¬¡æ•°å‘é€å¤±è´¥
request.timeout.ms=

# TCPçš„å‘é€ç¼“å­˜ SO_SNDBUF ç©ºé—´å¤§å°ï¼Œç”¨äºå‘é€æ•°æ®
send.buffer.bytes=

# æŒ‡å®šserverç­‰å¾…æ¥è‡ªfollowersçš„ç¡®è®¤çš„æœ€å¤§æ—¶é—´ï¼Œæ ¹æ®acksçš„è®¾ç½®ï¼Œè¶…æ—¶åˆ™è¿”å›error
timeout.ms=

# åœ¨blockå‰ä¸€ä¸ªconnectionä¸Šå…è®¸æœ€å¤§æœªç¡®è®¤çš„requestsæ•°é‡ã€‚
# å½“è®¾ä¸º1æ—¶ï¼Œå³æ˜¯æ¶ˆæ¯ä¿è¯æœ‰åºæ¨¡å¼ï¼Œæ³¨æ„ï¼šè¿™é‡Œçš„æ¶ˆæ¯ä¿è¯æœ‰åºæ˜¯æŒ‡å¯¹äºå•ä¸ªPartitionçš„æ¶ˆæ¯æœ‰é¡ºåºï¼Œå› æ­¤è‹¥è¦ä¿è¯å…¨å±€æ¶ˆæ¯æœ‰åºï¼Œå¯ä»¥åªä½¿ç”¨ä¸€ä¸ªPartitionï¼Œå½“ç„¶ä¹Ÿä¼šé™ä½æ€§èƒ½
max.in.flight.requests.per.connection=

# åœ¨ç¬¬ä¸€æ¬¡å°†æ•°æ®å‘é€åˆ°æŸtopicæ—¶ï¼Œéœ€å…ˆfetchè¯¥topicçš„metadataï¼Œå¾—çŸ¥å“ªäº›æœåŠ¡å™¨æŒæœ‰è¯¥topicçš„partitionï¼Œè¯¥å€¼ä¸ºæœ€é•¿è·å–metadataæ—¶é—´
metadata.fetch.timeout.ms=

# è¿æ¥å¤±è´¥æ—¶ï¼Œå½“æˆ‘ä»¬é‡æ–°è¿æ¥æ—¶çš„ç­‰å¾…æ—¶é—´
reconnect.backoff.ms=

# åœ¨é‡è¯•å‘é€å¤±è´¥çš„requestå‰çš„ç­‰å¾…æ—¶é—´ï¼Œé˜²æ­¢è‹¥ç›®çš„Brokerå®Œå…¨æŒ‚æ‰çš„æƒ…å†µä¸‹Producerä¸€ç›´é™·å…¥æ­»å¾ªç¯å‘é€ï¼ŒæŠ˜ä¸­çš„æ–¹æ³•
retry.backoff.ms=

# metricsç³»ç»Ÿç»´æŠ¤å¯é…ç½®çš„æ ·æœ¬æ•°é‡ï¼Œåœ¨ä¸€ä¸ªå¯ä¿®æ­£çš„window size
metrics.sample.window.ms=30000

# ç”¨äºç»´æŠ¤metricsçš„æ ·æœ¬æ•°
metrics.num.samples=2

# ç±»çš„åˆ—è¡¨ï¼Œç”¨äºè¡¡é‡æŒ‡æ ‡ã€‚å®ç°MetricReporteræ¥å£
metric.reporters=[]

# å¼ºåˆ¶åˆ·æ–°metadataçš„å‘¨æœŸï¼Œå³ä½¿leaderæ²¡æœ‰å˜åŒ–
metadata.max.age.ms=300000

# ä¸brokerä¼šè¯åè®®ï¼Œå–å€¼ï¼šLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
security.protocol=PLAINTEXT

# åˆ†åŒºç±»ï¼Œå®ç°Partitioneræ¥å£
partitioner.class=class org.apache.kafka.clients.producer.internals.DefaultPartitioner

# æ§åˆ¶blockçš„æ—¶é•¿ï¼Œå½“bufferç©ºé—´ä¸å¤Ÿæˆ–è€…metadataä¸¢å¤±æ—¶äº§ç”Ÿblock
max.block.ms=60000

# å…³é—­è¾¾åˆ°è¯¥æ—¶é—´çš„ç©ºé—²è¿æ¥
connections.max.idle.ms=540000

# å½“å‘serverå‘å‡ºè¯·æ±‚æ—¶ï¼Œè¿™ä¸ªå­—ç¬¦ä¸²ä¼šå‘é€ç»™serverï¼Œç›®çš„æ˜¯èƒ½å¤Ÿè¿½è¸ªè¯·æ±‚æº
client.id=""

# å‘ç”Ÿé”™è¯¯æ—¶ï¼Œé‡ä¼ æ¬¡æ•°ã€‚å½“å¼€å¯é‡ä¼ æ—¶ï¼Œéœ€è¦å°†`max.in.flight.requests.per.connection`è®¾ç½®ä¸º1ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´å¤±åº
retries=0

# key åºåˆ—åŒ–æ–¹å¼ï¼Œç±»å‹ä¸ºclassï¼Œéœ€å®ç°Serializer interface
key.serializer=

# value åºåˆ—åŒ–æ–¹å¼ï¼Œç±»å‹ä¸ºclassï¼Œéœ€å®ç°Serializer interface
value.serializer=

</code></pre></div></div>

<ul>
  <li>Consumerä¸»è¦é…ç½®ï¼š<a href="http://kafka.apache.org/documentation.html#newconsumerconfigs">å®˜æ–¹æ–‡æ¡£</a></li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># ç”¨äºå»ºç«‹ä¸kafkaé›†ç¾¤çš„è¿æ¥ï¼Œè¿™ä¸ªlistä»…ä»…å½±å“ç”¨äºåˆå§‹åŒ–çš„hostsï¼Œæ¥å‘ç°å…¨éƒ¨çš„serversã€‚
bootstrap.servers=

# ç”¨æ¥å”¯ä¸€æ ‡è¯†consumerè¿›ç¨‹æ‰€åœ¨ç»„çš„å­—ç¬¦ä¸²
group.id=

# å•æ¬¡æ‹‰å–çš„æœ€å¤§æ¶ˆæ¯æ¡æ•°
max.poll.records=

# consumerå¤±æ•ˆæ—¶é—´ï¼Œå½“é•¿æ—¶é—´æœªæ”¶åˆ°å¿ƒè·³ï¼Œå¹¶ä¸”å¤§äºè¿™ä¸ªæ—¶é—´ï¼Œbrokerä¼šå°†è¿™ä¸ªconsumerä»groupä¸­ç§»é™¤
session.timeout.ms

# å¿ƒè·³é—´éš”ï¼Œéœ€ä½äºsession.timeout.msæ—¶é—´ï¼Œå»ºè®®ä¸é«˜äºå…¶1/3
heartbeat.interval.ms

# å¦‚æœè®¾ä¸ºtrueï¼Œconsumerçš„offsetå°†åœ¨åå°å®šæœŸè‡ªåŠ¨æäº¤
enable.auto.commit

# å½“enable.auto.commitè®¾ä¸ºtrueæ—¶ï¼Œå®šæœŸæäº¤çš„æ—¶é—´é—´éš”(ms)
auto.commit.interval.ms

# åˆ†åŒºç­–ç•¥ï¼Œå–å€¼ä¸ºrangeæˆ–roundrobin
partition.assignment.strategy

# è‡ªåŠ¨é‡ç½®offsetï¼Œå–å€¼earliestã€latestã€none
# earliestå°†offsetè®¾ç½®ä¸ºå¼€å§‹ä½ç½®
# latestå°†offsetè®¾ç½®ä¸ºå¼€å§‹ä½ç½®
auto.offset.reset

# æ¯æ¬¡æœ€å°æ‹‰å–çš„æ¶ˆæ¯å¤§å°ï¼ˆbyteï¼‰ã€‚Consumerä¼šç­‰å¾…æ¶ˆæ¯ç§¯ç´¯åˆ°ä¸€å®šå°ºå¯¸åè¿›è¡Œæ‰¹é‡æ‹‰å–ã€‚é»˜è®¤ä¸º1ï¼Œä»£è¡¨æœ‰ä¸€æ¡å°±æ‹‰ä¸€æ¡
fetch.min.bytes

# æ‹‰å–æ¶ˆæ¯çš„æœ€å¤§å€¼
fetch.max.bytes

# å½“æ¶ˆæ¯æ²¡æœ‰ç§¯ç´¯åˆ°fetch.min.byteså€¼çš„æœ€å¤§ç­‰å¾…æ—¶é—´
fetch.max.wait.ms

# å…ƒæ•°æ®åˆ·æ–°æ—¶é—´(æ— ä»»ä½•æ”¹å˜çš„æƒ…å†µä¸‹)
metadata.max.age.ms

# æ¯æ¬¡ä»å•ä¸ªåˆ†åŒºä¸­æ‹‰å–çš„æ¶ˆæ¯æœ€å¤§å°ºå¯¸ï¼ˆbyteï¼‰ï¼Œé»˜è®¤ä¸º1M
max.partition.fetch.bytes

# tcpå‘é€bufferæ•°æ®çš„å¤§å°ï¼Œå¦‚æœå€¼ä¸º-1ï¼Œåˆ™ä¸ºosé»˜è®¤å€¼
send.buffer.bytes

# tcpè¯»å–bufferæ•°æ®çš„å¤§å°ï¼Œå¦‚æœå€¼ä¸º-1ï¼Œåˆ™ä¸ºosé»˜è®¤å€¼
receive.buffer.bytes

# å®¢æˆ·ç«¯id
client.id

# è¿æ¥æ—¶é—´é—´éš”
reconnect.backoff.ms

# è¿æ¥å¤±è´¥ï¼Œé‡è¿æ—¶é—´é—´éš”
retry.backoff.ms

# æ˜¯å¦å¼€å¯CRC32æ ¡éªŒï¼Œé»˜è®¤ä¸ºå¼€å¯
check.crcs

# æŒ‡å®škeyçš„ååºåˆ—åŒ–æ–¹å¼
key.deserializer

# æŒ‡å®švalueçš„ååºåˆ—åŒ–æ–¹å¼
value.deserializer

# å…³é—­è¿æ¥çš„æœ€å¤§ç©ºé—²æ—¶é—´ï¼Œé»˜è®¤ä¸º540000ms
connections.max.idle.ms

# å®¢æˆ·ç«¯ç­‰å¾…å“åº”æœ€å¤§æ—¶é—´
request.timeout.ms

# æ‹¦æˆªå™¨åˆ—è¡¨ï¼Œé»˜è®¤æ²¡æœ‰æ‹¦æˆªå™¨
interceptor.classes

# å†…éƒ¨topicsä¿¡æ¯æ˜¯å¦å¯è®¿é—®ï¼Œé»˜è®¤ä¸ºtrue
exclude.internal.topics

</code></pre></div></div>

<h2 id="äºŒé€šè¿‡javaä»£ç è¿›å…¥å¯¹kafkaçš„å­¦ä¹ ">äºŒã€é€šè¿‡JAVAä»£ç è¿›å…¥å¯¹Kafkaçš„å­¦ä¹ </h2>
<ul>
  <li>æ„å»ºmavené¡¹ç›®ï¼Œå¼•å…¥ä¾èµ–</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
    &lt;version&gt;0.10.2.1&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></div></div>

<h3 id="21-producer-å‘å¸ƒæ¶ˆæ¯">2.1 producer å‘å¸ƒæ¶ˆæ¯</h3>

<ul>
  <li>Producer JAVAä»£ç </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.Properties;
import java.util.concurrent.Future;

/**
 * Created by Gao on 2017/5/13.
 */
public class ProducerDemo {
    private Producer&lt;String,String&gt; producer;
    private Logger logger= LoggerFactory.getLogger(ProducerDemo.class);

    public ProducerDemo() {
        //produceré…ç½®ä¿¡æ¯
        Properties config=new Properties();
        config.setProperty("bootstrap.servers","192.168.127.10:9092,192.168.127.11:9092,192.168.127.12:9092");
        config.setProperty("value.serializer","org.apache.kafka.common.serialization.StringSerializer");
        config.setProperty("key.serializer","org.apache.kafka.common.serialization.StringSerializer");
        config.setProperty("acks","0");
        producer=new KafkaProducer&lt;String, String&gt;(config);
    }
	//è¿™é‡Œæˆ‘ä»¬å¹¶æ²¡æœ‰æŒ‡å®špartit
    public void send(String topicName,String message){
        if(topicName==null||message==null){
            return;
        }
		//åˆ›å»ºæ¶ˆæ¯å®ä½“
        ProducerRecord&lt;String,String&gt; record=new ProducerRecord&lt;String, String&gt;(topicName,message);
        Future&lt;RecordMetadata&gt; future = producer.send(record);
        System.out.println("send message ["+message+"] success");
        producer.flush();
    }

    public void close(){
        if(producer!=null){
            producer.close();
        }
    }

    public static void main(String[] args) {
        int i = 1;
        while(true) {
            new ProducerDemo().send("kafka_study", "hello" + i++);
            try {
                Thread.sleep(600);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }
}

</code></pre></div></div>
<h4 id="211-å†™å…¥æ–¹å¼">2.1.1 å†™å…¥æ–¹å¼</h4>
<blockquote>
  <p>producer é‡‡ç”¨ push æ¨¡å¼å°†æ¶ˆæ¯å‘å¸ƒåˆ° brokerï¼Œæ¯æ¡æ¶ˆæ¯éƒ½è¢« append åˆ° patition ä¸­ï¼Œå±äºé¡ºåºå†™ç£ç›˜ï¼ˆé¡ºåºå†™ç£ç›˜æ•ˆç‡æ¯”éšæœºå†™å†…å­˜è¦é«˜ï¼Œä¿éšœ kafka ååç‡ï¼‰ã€‚</p>
</blockquote>

<h4 id="212-æ¶ˆæ¯è·¯ç”±">2.1.2 æ¶ˆæ¯è·¯ç”±</h4>
<blockquote>
  <p>producer å‘é€æ¶ˆæ¯åˆ° broker æ—¶ï¼Œä¼šæ ¹æ®åˆ†åŒºç®—æ³•é€‰æ‹©å°†å…¶å­˜å‚¨åˆ°å“ªä¸€ä¸ª partitionã€‚å…¶è·¯ç”±æœºåˆ¶ä¸ºï¼š</p>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. æŒ‡å®šäº† patitionï¼Œåˆ™ç›´æ¥ä½¿ç”¨ï¼›
2. æœªæŒ‡å®š patition ä½†æŒ‡å®š keyï¼Œé€šè¿‡å¯¹ key çš„ value è¿›è¡Œhash é€‰å‡ºä¸€ä¸ª patitionï¼Œé€šè¿‡è¿™æ ·çš„æ–¹æ¡ˆï¼Œkafkaèƒ½å¤Ÿç¡®ä¿ç›¸åŒkeyå€¼çš„æ•°æ®å¯ä»¥å†™å…¥åŒä¸€ä¸ªpartition
3. patition å’Œ key éƒ½æœªæŒ‡å®šï¼Œä½¿ç”¨è½®è¯¢é€‰å‡ºä¸€ä¸ª patitionã€‚
</code></pre></div>  </div>
  <p>ä¸‹é¢æ˜¯ä¸€äº›kafka client å¯¹äºåˆ†åŒºçš„ä¸€äº›æºç ç‰‡æ®µ</p>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>//åˆ›å»ºæ¶ˆæ¯å®ä¾‹
public ProducerRecord(String topic, Integer partition, Long timestamp, K key, V value) {
        if (topic == null)
            throw new IllegalArgumentException("Topic cannot be null.");
        if (timestamp != null &amp;&amp; timestamp &lt; 0)
            throw new IllegalArgumentException(
                    String.format("Invalid timestamp: %d. Timestamp should always be non-negative or null.", timestamp));
        if (partition != null &amp;&amp; partition &lt; 0)
            throw new IllegalArgumentException(
                    String.format("Invalid partition: %d. Partition number should always be non-negative or null.", partition));
        this.topic = topic;
        this.partition = partition;
        this.key = key;
        this.value = value;
        this.timestamp = timestamp;
    }
</code></pre></div>  </div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {
    Integer partition = record.partition();
	//å¦‚æœpartitionä¸ä¸ºnullå°±ç›´æ¥ä½¿ç”¨ï¼Œå¦‚æœä¸ºnullåˆ™è¿›è¡Œç›¸åº”è®¡ç®—
    return partition != null ?
            partition :
            partitioner.partition(
                    record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);
}
</code></pre></div>  </div>
  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>//è®¡ç®—å†™å…¥çš„partitionã€‚
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
	//å¦‚æœkeyä¸ºnull,è½®è¯¢é€‰å‡ºä¸€ä¸ª patition
    if (keyBytes == null) {
        int nextValue = nextValue(topic);
        List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);
        if (availablePartitions.size() &gt; 0) {
            int part = Utils.toPositive(nextValue) % availablePartitions.size();
            return availablePartitions.get(part).partition();
        } else {
            // no partitions are available, give a non-available partition
            return Utils.toPositive(nextValue) % numPartitions;
        }
    } else {
		//KEYä¸ä¸ºnullåˆ™é€šè¿‡å¯¹keyçš„keyBytesè¿›è¡Œhashè®¡ç®—å‡ºä¸€ä¸ªpartition
        // hash the keyBytes to choose a partition
        return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
</code></pre></div>  </div>
</blockquote>

<h4 id="213-æ¶ˆæ¯å†™å…¥æµç¨‹">2.1.3 æ¶ˆæ¯å†™å…¥æµç¨‹</h4>
<blockquote>
  <ol>
    <li>producer å…ˆä» zookeeper çš„ â€œ/brokers/â€¦/stateâ€ èŠ‚ç‚¹æ‰¾åˆ°è¯¥ partition çš„ leader</li>
    <li>producer å°†æ¶ˆæ¯å‘é€ç»™è¯¥ leader</li>
    <li>leader å°†æ¶ˆæ¯å†™å…¥æœ¬åœ° log</li>
    <li>followers ä» leader pull æ¶ˆæ¯ï¼Œå†™å…¥æœ¬åœ° log åå‘ leader å‘é€ ACK</li>
    <li>leader æ”¶åˆ°æ‰€æœ‰ ISR (In-Sync Replicas) ä¸­çš„ replica çš„ ACK åï¼Œå¢åŠ  HWï¼ˆhigh watermarkï¼Œæœ€å commit çš„ offsetï¼‰ å¹¶å‘ producer å‘é€ ACK</li>
  </ol>
</blockquote>

<h3 id="22-broker-ä¿å­˜æ¶ˆæ¯">2.2 broker ä¿å­˜æ¶ˆæ¯</h3>
<h4 id="221-å­˜å‚¨æ–¹å¼">2.2.1 å­˜å‚¨æ–¹å¼</h4>
<p>ç‰©ç†ä¸ŠæŠŠ topic åˆ†æˆä¸€ä¸ªæˆ–å¤šä¸ª patitionï¼ˆå¯¹åº” server.properties ä¸­çš„ num.partitions=3 é…ç½®ï¼‰ï¼Œæ¯ä¸ª patition ç‰©ç†ä¸Šå¯¹åº”ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼ˆè¯¥æ–‡ä»¶å¤¹å­˜å‚¨è¯¥ patition çš„æ‰€æœ‰æ¶ˆæ¯å’Œç´¢å¼•æ–‡ä»¶ä»¥åŠkafkaçš„å…·ä½“æ—¶é—´æ—¥å¿—ï¼‰ï¼Œå•ä¸ªbrokerå’Œå¤šä¸ªbrokerçš„partitionç•¥æœ‰åŒºåˆ«ï¼š</p>

<ul>
  <li>
    <p>å•ä¸ªBrokerï¼š
ã€€ã€€åˆ›å»ºä¸€ä¸ªpartitionä¸º3ï¼ŒReplicaä¸º1ï¼ŒTopicåå­—ä¸ºkafka_studyçš„topicã€‚æˆ‘ä»¬å¾—åˆ°çš„åˆ†å¸ƒå¼åœ¨é…ç½®å¥½çš„LOGæ–‡ä»¶å¤¹ä¸­ç”Ÿæˆä¸‰ä¸ªåˆ†åˆ«ä¸ºï¼škafka_study-0ã€kafka_study-1ã€kafka_study-2çš„æ–‡ä»¶å¤¹ç”¨æ¥å­˜å‚¨Partitionä¸‹çš„ä¿¡æ¯çš„.indexæ–‡ä»¶.logæ–‡ä»¶å’Œ.timeindexæ–‡ä»¶ã€‚</p>
  </li>
  <li>
    <p>å¤šä¸ªBrokerï¼š
ã€€ã€€åˆ›å»ºä¸€ä¸ªpartitionä¸º3ï¼ŒReplicaä¸º1ï¼ŒTopicåå­—ä¸ºkafka_studyçš„topicã€‚æˆ‘ä»¬åœ¨Broker0ä¸­å¯¹åº”çš„LOGæ–‡ä»¶å¤¹ä¸­åªæ˜¯å‘ç°äº†kafka_study-0çš„æ–‡ä»¶å¤¹ï¼Œåœ¨å…¶ä»–Brokerä¸­åˆ†åˆ«å‘ç°äº†Partitionçš„æ–‡ä»¶å¤¹ã€‚å¦‚æœBrokeræ•°å¤§äºPartitionæ•°ï¼Œé‚£ä¹ˆæœ‰Brokerä¸­æ²¡æœ‰å¯¹åº”çš„Partitionï¼›å¦‚æœBrokerå°äºPartitionæ•°ï¼ŒBrokerä¸­ä¼šå­˜åœ¨å¤šä¸ªPartitionã€‚</p>
  </li>
</ul>

<p>æˆ‘ä»¬æ­å»ºçš„æ˜¯ä¸‰ä¸ªbrokerçš„é›†ç¾¤ï¼Œæ•…partitionåˆ†å¸ƒå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>

<p><img src="/images/gaoxiaobo/kafka3.png" alt="" /></p>

<p>è¿›å…¥partitionå¯¹åº”çš„æ–‡ä»¶å¤¹å¯ä»¥çœ‹åˆ°ä¸‰ä¸ªæ–‡ä»¶ï¼Œå¦‚ä¸‹å›¾ï¼š
<img src="/images/gaoxiaobo/kafka4.png" alt="" /></p>
<ul>
  <li>indexæ–‡ä»¶ä¸ºç´¢å¼•æ–‡ä»¶ï¼Œå‘½åè§„åˆ™ä¸ºä»0å¼€å§‹åˆ°ï¼Œåç»­çš„ç”±ä¸Šä¸€ä¸ªæ–‡ä»¶çš„æœ€å¤§çš„offsetåç§»é‡æ¥å¼€å¤´ï¼ˆ19ä½æ•°å­—å­—ç¬¦é•¿åº¦ï¼‰</li>
  <li>logæ–‡ä»¶ä¸ºæ•°æ®æ–‡ä»¶ï¼Œå­˜æ”¾å…·ä½“æ¶ˆæ¯æ•°æ®</li>
  <li>timeindexæ–‡ä»¶ï¼Œæ˜¯kafkaçš„å…·ä½“æ—¶é—´æ—¥å¿—</li>
</ul>

<p>åˆ†åŒºç®—æ³•ï¼š</p>
<ul>
  <li>åˆ†åŒºæ•°=Tt/Max(Tp,Tc)</li>
  <li>Tp:producerååé‡ Tc:consumerååé‡ Ttç›®æ ‡çš„ååé‡</li>
</ul>

<p>####2.2.2 æ¶ˆæ¯çš„å­˜å‚¨ä¸åˆ é™¤
æ— è®ºæ¶ˆæ¯æ˜¯å¦è¢«æ¶ˆè´¹ï¼Œkafka éƒ½ä¼šä¿ç•™æ‰€æœ‰æ¶ˆæ¯ã€‚æœ‰ä¸¤ç§ç­–ç•¥å¯ä»¥åˆ é™¤æ—§æ•°æ®ï¼š</p>
<blockquote>
  <ol>
    <li>åŸºäºæ—¶é—´ï¼šlog.retention.hours=168</li>
    <li>åŸºäºå¤§å°ï¼šlog.retention.bytes=1073741824</li>
  </ol>
</blockquote>

<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºKafkaè¯»å–ç‰¹å®šæ¶ˆæ¯çš„æ—¶é—´å¤æ‚åº¦ä¸ºO(1)ï¼Œå³ä¸æ–‡ä»¶å¤§å°æ— å…³ï¼Œæ‰€ä»¥è¿™é‡Œåˆ é™¤è¿‡æœŸæ–‡ä»¶ä¸æé«˜ Kafka æ€§èƒ½æ— å…³ã€‚</p>

<p>###2.3 consumer æ¶ˆè´¹æ¶ˆæ¯
Kafka 0.10.2.1æä¾›äº†ä¸¤å¥—<strong><em>Consumer</em></strong> APIå…±æˆ‘ä»¬ä½¿ç”¨ï¼š</p>
<ol>
  <li><strong><em>MockConsumer</em></strong></li>
  <li><strong><em>KafkaConsumer</em></strong></li>
</ol>

<p>MockConsumerä¸»è¦ä¾›å¼€å‘æµ‹è¯•æ—¶ä½¿ç”¨ï¼Œè¿™é‡Œä½¿ç”¨çš„æ˜¯KafkaConsumerã€‚</p>
<ul>
  <li>Consumer JAVAä»£ç </li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import org.apache.kafka.clients.consumer.*;

import java.util.*;

/**
 * Created by Gao on 2017/5/13.
 */
public class ConsumerDemo {
    private Consumer&lt;String,String&gt; consumer;
    private String topicName;
    private String groupId;

    public ConsumerDemo(String topicName,String groupId) {
        this.topicName=topicName;
        this.groupId=groupId;
        //consumeré…ç½®ä¿¡æ¯
        Properties config=new Properties();
        config.setProperty("group.id",groupId);
        config.setProperty("bootstrap.servers","192.168.127.10:9092,192.168.127.11:9092,192.168.127.12:9092");
        config.setProperty("enable.auto.commit","true");
        //è®¾ç½®offsetä»å¤´å¼€å§‹
        config.setProperty("auto.offset.reset","earliest");
        config.setProperty("key.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
        config.setProperty("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
        config.setProperty("auto.commit.interval.ms","60000");
        //åˆ›å»ºConsumerå®ä¾‹
        this.consumer = new KafkaConsumer&lt;String, String&gt;(config);
    }

    public void receive(){
        List&lt;String&gt; topics=new ArrayList&lt;String&gt;();
        topics.add(topicName);
		//è®¢é˜…æ¶ˆæ¯
        consumer.subscribe(topics);
       while (true){
			//æ‹‰å–æ¶ˆæ¯
           ConsumerRecords&lt;String, String&gt; records = consumer.poll(1000);
           for (ConsumerRecord&lt;String,String&gt; record:records) {
               System.out.println(record.toString());
           }
           System.out.println(records.count());

           try {
               Thread.sleep(1000);
           } catch (InterruptedException e) {
               e.printStackTrace();
           }
       }
    }

    public static void main(String[] args) {
        new ConsumerDemo("kafka_study","test-group").receive();
    }
}


</code></pre></div></div>

<p>####2.3.1 Consumer Group</p>
<blockquote>
  <p>kafka çš„åˆ†é…å•ä½æ˜¯ patitionã€‚æ¯ä¸ª consumer éƒ½å±äºä¸€ä¸ª groupï¼Œä¸€ä¸ª partition åªèƒ½è¢«åŒä¸€ä¸ª group å†…çš„ä¸€ä¸ª consumer æ‰€æ¶ˆè´¹ï¼ˆä¹Ÿå°±ä¿éšœäº†ä¸€ä¸ªæ¶ˆæ¯åªèƒ½è¢« group å†…çš„ä¸€ä¸ª consuemr æ‰€æ¶ˆè´¹ï¼‰ï¼Œä½†æ˜¯å¤šä¸ª group å¯ä»¥åŒæ—¶æ¶ˆè´¹è¿™ä¸ª partitionã€‚</p>
</blockquote>

<p>####2.3.2 æ¶ˆè´¹æ–¹å¼</p>
<blockquote>
  <p>consumer é‡‡ç”¨ pull æ¨¡å¼ä» broker ä¸­è¯»å–æ•°æ®ã€‚
push æ¨¡å¼å¾ˆéš¾é€‚åº”æ¶ˆè´¹é€Ÿç‡ä¸åŒçš„æ¶ˆè´¹è€…ï¼Œå› ä¸ºæ¶ˆæ¯å‘é€é€Ÿç‡æ˜¯ç”± broker å†³å®šçš„ã€‚å®ƒçš„ç›®æ ‡æ˜¯å°½å¯èƒ½ä»¥æœ€å¿«é€Ÿåº¦ä¼ é€’æ¶ˆæ¯ï¼Œä½†æ˜¯è¿™æ ·å¾ˆå®¹æ˜“é€ æˆ consumer æ¥ä¸åŠå¤„ç†æ¶ˆæ¯ï¼Œå…¸å‹çš„è¡¨ç°å°±æ˜¯æ‹’ç»æœåŠ¡ä»¥åŠç½‘ç»œæ‹¥å¡ã€‚è€Œ pull æ¨¡å¼åˆ™å¯ä»¥æ ¹æ® consumer çš„æ¶ˆè´¹èƒ½åŠ›ä»¥é€‚å½“çš„é€Ÿç‡æ¶ˆè´¹æ¶ˆæ¯ã€‚
å¯¹äº Kafka è€Œè¨€ï¼Œpull æ¨¡å¼æ›´åˆé€‚ï¼Œå®ƒå¯ç®€åŒ– broker çš„è®¾è®¡ï¼Œconsumer å¯è‡ªä¸»æ§åˆ¶æ¶ˆè´¹æ¶ˆæ¯çš„é€Ÿç‡ï¼ŒåŒæ—¶ consumer å¯ä»¥è‡ªå·±æ§åˆ¶æ¶ˆè´¹æ–¹å¼â€”â€”å³å¯æ‰¹é‡æ¶ˆè´¹ä¹Ÿå¯é€æ¡æ¶ˆè´¹ï¼ŒåŒæ—¶è¿˜èƒ½é€‰æ‹©ä¸åŒçš„æäº¤æ–¹å¼ä»è€Œå®ç°ä¸åŒçš„ä¼ è¾“è¯­ä¹‰ã€‚</p>
</blockquote>

<p>####2.3.3æ¶ˆæ¯ä¼ é€’ä¿éšœ</p>

<p>ç°åœ¨æˆ‘ä»¬äº†è§£ä¸€äº›å…³äºç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥è®¨è®ºkafkaæä¾›äº†ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…ä¹‹é—´çš„ä¼ è¾“è¯­ä¹‰ï¼š<a href="http://kafka.apache.org/documentation.html#semantics">å®˜æ–¹æ–‡æ¡£</a></p>

<ul>
  <li><strong>At most once</strong>
æœ€å¤šä¸€æ¬¡ â€” æ¶ˆæ¯å¯èƒ½ä¸¢å¤±ï¼Œä½†ç»ä¸ä¼šé‡å‘ã€‚</li>
  <li><strong>At least once</strong>
è‡³å°‘ä¸€æ¬¡ â€” æ¶ˆæ¯ç»ä¸ä¼šä¸¢å¤±ï¼Œä½†æœ‰å¯èƒ½é‡æ–°å‘é€ã€‚</li>
  <li><strong>Exactly once</strong>
æ­£å¥½ä¸€æ¬¡ â€” è¿™æ˜¯äººä»¬çœŸæ­£æƒ³è¦çš„ï¼Œæ¯ä¸ªæ¶ˆæ¯ä¼ é€’ä¸€æ¬¡ä¸”ä»…ä¸€æ¬¡ã€‚</li>
</ul>

<p>å¦‚æœå°† consumer è®¾ç½®ä¸º autocommitï¼Œconsumer ä¸€æ—¦è¯»åˆ°æ•°æ®ç«‹å³è‡ªåŠ¨ commitã€‚å¦‚æœåªè®¨è®ºè¿™ä¸€è¯»å–æ¶ˆæ¯çš„è¿‡ç¨‹ï¼Œé‚£ Kafka ç¡®ä¿äº† Exactly onceã€‚</p>

<p>ä½†å®é™…ä½¿ç”¨ä¸­åº”ç”¨ç¨‹åºå¹¶éåœ¨ consumer è¯»å–å®Œæ•°æ®å°±ç»“æŸäº†ï¼Œè€Œæ˜¯è¦è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†ï¼Œè€Œæ•°æ®å¤„ç†ä¸ commit çš„é¡ºåºåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå†³å®šäº†consumer delivery guaranteeï¼š</p>

<ol>
  <li>è¯»å®Œæ¶ˆæ¯ å…ˆcommit å†å¤„ç†æ¶ˆæ¯ã€‚
 è¿™ç§æ¨¡å¼ä¸‹ï¼Œå¦‚æœ consumer åœ¨ commit åè¿˜æ²¡æ¥å¾—åŠå¤„ç†æ¶ˆæ¯å°± crash äº†ï¼Œä¸‹æ¬¡é‡æ–°å¼€å§‹å·¥ä½œåå°±æ— æ³•è¯»åˆ°åˆšåˆšå·²æäº¤è€Œæœªå¤„ç†çš„æ¶ˆæ¯ï¼Œè¿™å°±å¯¹åº”äº At most once</li>
  <li>è¯»å®Œæ¶ˆæ¯å…ˆå¤„ç†å† commitã€‚
 è¿™ç§æ¨¡å¼ä¸‹ï¼Œå¦‚æœåœ¨å¤„ç†å®Œæ¶ˆæ¯ä¹‹å commit ä¹‹å‰ consumer crash äº†ï¼Œä¸‹æ¬¡é‡æ–°å¼€å§‹å·¥ä½œæ—¶è¿˜ä¼šå¤„ç†åˆšåˆšæœª commit çš„æ¶ˆæ¯ï¼Œå®é™…ä¸Šè¯¥æ¶ˆæ¯å·²ç»è¢«å¤„ç†è¿‡äº†ã€‚è¿™å°±å¯¹åº”äº At least onceã€‚</li>
  <li>å¦‚æœä¸€å®šè¦åšåˆ° Exactly onceï¼Œå°±éœ€è¦åè°ƒ offset å’Œå®é™…æ“ä½œçš„è¾“å‡ºã€‚
 ç²¾å…¸çš„åšæ³•æ˜¯å¼•å…¥ä¸¤é˜¶æ®µæäº¤ã€‚å¦‚æœèƒ½è®© offset å’Œæ“ä½œè¾“å…¥å­˜åœ¨åŒä¸€ä¸ªåœ°æ–¹ï¼Œä¼šæ›´ç®€æ´å’Œé€šç”¨ã€‚è¿™ç§æ–¹å¼å¯èƒ½æ›´å¥½ï¼Œå› ä¸ºè®¸å¤šè¾“å‡ºç³»ç»Ÿå¯èƒ½ä¸æ”¯æŒä¸¤é˜¶æ®µæäº¤ã€‚æ¯”å¦‚ï¼Œconsumer æ‹¿åˆ°æ•°æ®åå¯èƒ½æŠŠæ•°æ®æ”¾åˆ° HDFSï¼Œå¦‚æœæŠŠæœ€æ–°çš„ offset å’Œæ•°æ®æœ¬èº«ä¸€èµ·å†™åˆ° HDFSï¼Œé‚£å°±å¯ä»¥ä¿è¯æ•°æ®çš„è¾“å‡ºå’Œ offset çš„æ›´æ–°è¦ä¹ˆéƒ½å®Œæˆï¼Œè¦ä¹ˆéƒ½ä¸å®Œæˆï¼Œé—´æ¥å®ç° Exactly onceã€‚</li>
</ol>

<p>å‚è€ƒæ–‡ç« ï¼š</p>
<ol>
  <li><a href="http://kafka.apache.org/documentation.html">Kafka 0.10.2 Documentation</a></li>
  <li><a href="http://www.cnblogs.com/cyfonly/p/5954614.html">kafkaå­¦ä¹ ç¬”è®°ï¼šçŸ¥è¯†ç‚¹æ•´ç†</a></li>
  <li><a href="http://www.cnblogs.com/wangb0402/p/6182707.html">kafka-åˆ†å¸ƒå¼æ¶ˆæ¯ç³»ç»Ÿ</a></li>
  <li><a href="http://orchome.com/21">kafkaæ¶ˆæ¯ä¼ é€’ä¿éšœ</a></li>
</ol>

:ET