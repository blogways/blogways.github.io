I"¶C<h1 id="sparkç®€å•æ•™å­¦">Sparkç®€å•æ•™å­¦#</h1>

<h2 id="ä¸€sparkç®€ä»‹">ä¸€ã€Sparkç®€ä»‹</h2>

<p>Sparkæœ€åˆç”±ç¾å›½åŠ å·ä¼¯å…‹åˆ©å¤§å­¦ï¼ˆUCBerkeleyï¼‰çš„AMPï¼ˆAlgorithms, Machines and Peopleï¼‰å®éªŒå®¤äº2009å¹´å¼€å‘ï¼Œæ˜¯åŸºäºå†…å­˜è®¡ç®—çš„å¤§æ•°æ®å¹¶è¡Œè®¡ç®—æ¡†æ¶ï¼Œå¯ç”¨äºæ„å»ºå¤§å‹çš„ã€ä½å»¶è¿Ÿçš„æ•°æ®åˆ†æåº”ç”¨ç¨‹åºã€‚Sparkåœ¨è¯ç”Ÿä¹‹åˆå±äºç ”ç©¶æ€§é¡¹ç›®ï¼Œå…¶è¯¸å¤šæ ¸å¿ƒç†å¿µå‡æºè‡ªå­¦æœ¯ç ”ç©¶è®ºæ–‡ã€‚2013å¹´ï¼ŒSparkåŠ å…¥Apacheå­µåŒ–å™¨é¡¹ç›®åï¼Œå¼€å§‹è·å¾—è¿…çŒ›çš„å‘å±•ï¼Œå¦‚ä»Šå·²æˆä¸ºApacheè½¯ä»¶åŸºé‡‘ä¼šæœ€é‡è¦çš„ä¸‰å¤§åˆ†å¸ƒå¼è®¡ç®—ç³»ç»Ÿå¼€æºé¡¹ç›®ä¹‹ä¸€ï¼ˆå³Hadoopã€Sparkã€Stormï¼‰ã€‚</p>

<p>Sparkå…·æœ‰å¦‚ä¸‹å‡ ä¸ªä¸»è¦ç‰¹ç‚¹ï¼š</p>
<ul>
  <li>è¿è¡Œé€Ÿåº¦å¿«ï¼šSparkä½¿ç”¨å…ˆè¿›çš„DAGï¼ˆDirected Acyclic Graphï¼Œæœ‰å‘æ— ç¯å›¾ï¼‰æ‰§è¡Œå¼•æ“ï¼Œä»¥æ”¯æŒå¾ªç¯æ•°æ®æµä¸å†…å­˜è®¡ç®—ï¼ŒåŸºäºå†…å­˜çš„æ‰§è¡Œé€Ÿåº¦å¯æ¯”Hadoop MapReduceå¿«ä¸Šç™¾å€ï¼ŒåŸºäºç£ç›˜çš„æ‰§è¡Œé€Ÿåº¦ä¹Ÿèƒ½å¿«åå€ï¼›</li>
  <li>å®¹æ˜“ä½¿ç”¨ï¼šSparkæ”¯æŒä½¿ç”¨Scalaã€Javaã€Pythonå’ŒRè¯­è¨€è¿›è¡Œç¼–ç¨‹ï¼Œç®€æ´çš„APIè®¾è®¡æœ‰åŠ©äºç”¨æˆ·è½»æ¾æ„å»ºå¹¶è¡Œç¨‹åºï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡Spark Shellè¿›è¡Œäº¤äº’å¼ç¼–ç¨‹ï¼›</li>
  <li>é€šç”¨æ€§ï¼šSparkæä¾›äº†å®Œæ•´è€Œå¼ºå¤§çš„æŠ€æœ¯æ ˆï¼ŒåŒ…æ‹¬SQLæŸ¥è¯¢ã€æµå¼è®¡ç®—ã€æœºå™¨å­¦ä¹ å’Œå›¾ç®—æ³•ç»„ä»¶ï¼Œè¿™äº›ç»„ä»¶å¯ä»¥æ— ç¼æ•´åˆåœ¨åŒä¸€ä¸ªåº”ç”¨ä¸­ï¼Œè¶³ä»¥åº”å¯¹å¤æ‚çš„è®¡ç®—ï¼›</li>
  <li>è¿è¡Œæ¨¡å¼å¤šæ ·ï¼šSparkå¯è¿è¡Œäºç‹¬ç«‹çš„é›†ç¾¤æ¨¡å¼ä¸­ï¼Œæˆ–è€…è¿è¡ŒäºHadoopä¸­ï¼Œä¹Ÿå¯è¿è¡ŒäºAmazon EC2ç­‰äº‘ç¯å¢ƒä¸­ï¼Œå¹¶ä¸”å¯ä»¥è®¿é—®HDFSã€Cassandraã€HBaseã€Hiveç­‰å¤šç§æ•°æ®æºã€‚</li>
</ul>

<h2 id="äºŒsparkè¿è¡Œæ¶æ„">äºŒã€Sparkè¿è¡Œæ¶æ„</h2>
<p>Sparkæ¶æ„çš„ç»„æˆå›¾å¦‚ä¸‹ï¼š</p>

<p><img src="/images/shenbin3/spark/saprk_framework.png" alt="" /></p>

<ul>
  <li>Cluster Managerï¼šåœ¨standaloneæ¨¡å¼ä¸­å³ä¸ºMasterä¸»èŠ‚ç‚¹ï¼Œæ§åˆ¶æ•´ä¸ªé›†ç¾¤ï¼Œç›‘æ§workerã€‚åœ¨YARNæ¨¡å¼ä¸­ä¸ºèµ„æºç®¡ç†å™¨</li>
  <li>WorkerèŠ‚ç‚¹ï¼šä»èŠ‚ç‚¹ï¼Œè´Ÿè´£æ§åˆ¶è®¡ç®—èŠ‚ç‚¹ï¼Œå¯åŠ¨Executoræˆ–è€…Driverã€‚</li>
  <li>Driverï¼š è¿è¡ŒApplication çš„main()å‡½æ•°</li>
  <li>Executorï¼šæ‰§è¡Œå™¨ï¼Œæ˜¯ä¸ºæŸä¸ªApplicationè¿è¡Œåœ¨worker nodeä¸Šçš„ä¸€ä¸ªè¿›ç¨‹</li>
</ul>

<p>åœ¨Sparkä¸­ï¼Œä¸€ä¸ªåº”ç”¨ï¼ˆApplicationï¼‰ç”±ä¸€ä¸ªä»»åŠ¡æ§åˆ¶èŠ‚ç‚¹ï¼ˆDriverï¼‰å’Œè‹¥å¹²ä¸ªä½œä¸šï¼ˆJobï¼‰æ„æˆï¼Œä¸€ä¸ªä½œä¸šç”±å¤šä¸ªé˜¶æ®µï¼ˆStageï¼‰æ„æˆï¼Œä¸€ä¸ªé˜¶æ®µç”±å¤šä¸ªä»»åŠ¡ï¼ˆTaskï¼‰ç»„æˆã€‚å½“æ‰§è¡Œä¸€ä¸ªåº”ç”¨æ—¶ï¼Œä»»åŠ¡æ§åˆ¶èŠ‚ç‚¹ä¼šå‘é›†ç¾¤ç®¡ç†å™¨ï¼ˆCluster Managerï¼‰ç”³è¯·èµ„æºï¼Œå¯åŠ¨Executorï¼Œå¹¶å‘Executorå‘é€åº”ç”¨ç¨‹åºä»£ç å’Œæ–‡ä»¶ï¼Œç„¶ååœ¨Executorä¸Šæ‰§è¡Œä»»åŠ¡ï¼Œè¿è¡Œç»“æŸåï¼Œæ‰§è¡Œç»“æœä¼šè¿”å›ç»™ä»»åŠ¡æ§åˆ¶èŠ‚ç‚¹ï¼Œæˆ–è€…å†™åˆ°HDFSæˆ–è€…å…¶ä»–æ•°æ®åº“ä¸­ã€‚</p>

<p>Sparkçš„åŸºæœ¬è¿è¡Œæµç¨‹å¦‚ä¸‹ï¼š</p>

<p><img src="/images/shenbin3/spark/spark_flow.png" alt="" /></p>

<ol>
  <li>å½“ä¸€ä¸ªSparkåº”ç”¨è¢«æäº¤æ—¶ï¼Œé¦–å…ˆéœ€è¦ä¸ºè¿™ä¸ªåº”ç”¨æ„å»ºèµ·åŸºæœ¬çš„è¿è¡Œç¯å¢ƒï¼Œå³ç”±ä»»åŠ¡æ§åˆ¶èŠ‚ç‚¹ï¼ˆDriverï¼‰åˆ›å»ºä¸€ä¸ªSparkContextï¼Œç”±SparkContextè´Ÿè´£å’Œèµ„æºç®¡ç†å™¨ï¼ˆCluster Managerï¼‰çš„é€šä¿¡ä»¥åŠè¿›è¡Œèµ„æºçš„ç”³è¯·ã€ä»»åŠ¡çš„åˆ†é…å’Œç›‘æ§ç­‰ã€‚SparkContextä¼šå‘èµ„æºç®¡ç†å™¨æ³¨å†Œå¹¶ç”³è¯·è¿è¡ŒExecutorçš„èµ„æºï¼›</li>
  <li>èµ„æºç®¡ç†å™¨ä¸ºExecutoråˆ†é…èµ„æºï¼Œå¹¶å¯åŠ¨Executorè¿›ç¨‹ï¼ŒExecutorè¿è¡Œæƒ…å†µå°†éšç€â€œå¿ƒè·³â€å‘é€åˆ°èµ„æºç®¡ç†å™¨ä¸Šï¼›</li>
  <li>SparkContextæ ¹æ®RDDçš„ä¾èµ–å…³ç³»æ„å»ºDAGå›¾ï¼ŒDAGå›¾æäº¤ç»™DAGè°ƒåº¦å™¨ï¼ˆDAGSchedulerï¼‰è¿›è¡Œè§£æï¼Œå°†DAGå›¾åˆ†è§£æˆå¤šä¸ªâ€œé˜¶æ®µâ€ï¼ˆæ¯ä¸ªé˜¶æ®µéƒ½æ˜¯ä¸€ä¸ªä»»åŠ¡é›†ï¼‰ï¼Œå¹¶ä¸”è®¡ç®—å‡ºå„ä¸ªé˜¶æ®µä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç„¶åæŠŠä¸€ä¸ªä¸ªâ€œä»»åŠ¡é›†â€æäº¤ç»™åº•å±‚çš„ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆTaskSchedulerï¼‰è¿›è¡Œå¤„ç†ï¼›Executorå‘SparkContextç”³è¯·ä»»åŠ¡ï¼Œä»»åŠ¡è°ƒåº¦å™¨å°†ä»»åŠ¡åˆ†å‘ç»™Executorè¿è¡Œï¼ŒåŒæ—¶ï¼ŒSparkContextå°†åº”ç”¨ç¨‹åºä»£ç å‘æ”¾ç»™Executorï¼›</li>
  <li>ä»»åŠ¡åœ¨Executorä¸Šè¿è¡Œï¼ŒæŠŠæ‰§è¡Œç»“æœåé¦ˆç»™ä»»åŠ¡è°ƒåº¦å™¨ï¼Œç„¶ååé¦ˆç»™DAGè°ƒåº¦å™¨ï¼Œè¿è¡Œå®Œæ¯•åå†™å…¥æ•°æ®å¹¶é‡Šæ”¾æ‰€æœ‰èµ„æºã€‚</li>
</ol>

<h2 id="ä¸‰rdd">ä¸‰ã€RDD</h2>
<p>ä¸€ä¸ªRDDå°±æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼å¯¹è±¡é›†åˆï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåªè¯»çš„åˆ†åŒºè®°å½•é›†åˆï¼Œæ¯ä¸ªRDDå¯ä»¥åˆ†æˆå¤šä¸ªåˆ†åŒºï¼Œæ¯ä¸ªåˆ†åŒºå°±æ˜¯ä¸€ä¸ªæ•°æ®é›†ç‰‡æ®µï¼Œå¹¶ä¸”ä¸€ä¸ªRDDçš„ä¸åŒåˆ†åŒºå¯ä»¥è¢«ä¿å­˜åˆ°é›†ç¾¤ä¸­ä¸åŒçš„èŠ‚ç‚¹ä¸Šï¼Œä»è€Œå¯ä»¥åœ¨é›†ç¾¤ä¸­çš„ä¸åŒèŠ‚ç‚¹ä¸Šè¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚RDDæä¾›äº†ä¸€ç§é«˜åº¦å—é™çš„å…±äº«å†…å­˜æ¨¡å‹ï¼Œå³RDDæ˜¯åªè¯»çš„è®°å½•åˆ†åŒºçš„é›†åˆï¼Œä¸èƒ½ç›´æ¥ä¿®æ”¹ï¼Œåªèƒ½åŸºäºç¨³å®šçš„ç‰©ç†å­˜å‚¨ä¸­çš„æ•°æ®é›†æ¥åˆ›å»ºRDDï¼Œæˆ–è€…é€šè¿‡åœ¨å…¶ä»–RDDä¸Šæ‰§è¡Œç¡®å®šçš„è½¬æ¢æ“ä½œï¼ˆå¦‚mapã€joinå’ŒgroupByï¼‰è€Œåˆ›å»ºå¾—åˆ°æ–°çš„RDDã€‚RDDæä¾›äº†ä¸€ç»„ä¸°å¯Œçš„æ“ä½œä»¥æ”¯æŒå¸¸è§çš„æ•°æ®è¿ç®—ï¼Œåˆ†ä¸ºâ€œè¡ŒåŠ¨â€ï¼ˆActionï¼‰å’Œâ€œè½¬æ¢â€ï¼ˆTransformationï¼‰ä¸¤ç§ç±»å‹ï¼Œå‰è€…ç”¨äºæ‰§è¡Œè®¡ç®—å¹¶æŒ‡å®šè¾“å‡ºçš„å½¢å¼ï¼Œåè€…æŒ‡å®šRDDä¹‹é—´çš„ç›¸äº’ä¾èµ–å…³ç³»ã€‚ä¸¤ç±»æ“ä½œçš„ä¸»è¦åŒºåˆ«æ˜¯ï¼Œè½¬æ¢æ“ä½œï¼ˆæ¯”å¦‚mapã€filterã€groupByã€joinç­‰ï¼‰æ¥å—RDDå¹¶è¿”å›RDDï¼Œè€Œè¡ŒåŠ¨æ“ä½œï¼ˆæ¯”å¦‚countã€collectç­‰ï¼‰æ¥å—RDDä½†æ˜¯è¿”å›éRDDï¼ˆå³è¾“å‡ºä¸€ä¸ªå€¼æˆ–ç»“æœï¼‰ã€‚RDDæä¾›çš„è½¬æ¢æ¥å£éƒ½éå¸¸ç®€å•ï¼Œéƒ½æ˜¯ç±»ä¼¼mapã€filterã€groupByã€joinç­‰ç²—ç²’åº¦çš„æ•°æ®è½¬æ¢æ“ä½œï¼Œè€Œä¸æ˜¯é’ˆå¯¹æŸä¸ªæ•°æ®é¡¹çš„ç»†ç²’åº¦ä¿®æ”¹ã€‚å› æ­¤ï¼ŒRDDæ¯”è¾ƒé€‚åˆå¯¹äºæ•°æ®é›†ä¸­å…ƒç´ æ‰§è¡Œç›¸åŒæ“ä½œçš„æ‰¹å¤„ç†å¼åº”ç”¨ï¼Œè€Œä¸é€‚åˆç”¨äºéœ€è¦å¼‚æ­¥ã€ç»†ç²’åº¦çŠ¶æ€çš„åº”ç”¨ï¼Œæ¯”å¦‚Webåº”ç”¨ç³»ç»Ÿã€å¢é‡å¼çš„ç½‘é¡µçˆ¬è™«ç­‰ã€‚æ­£å› ä¸ºè¿™æ ·ï¼Œè¿™ç§ç²—ç²’åº¦è½¬æ¢æ¥å£è®¾è®¡ï¼Œä¼šä½¿äººç›´è§‰ä¸Šè®¤ä¸ºRDDçš„åŠŸèƒ½å¾ˆå—é™ã€ä¸å¤Ÿå¼ºå¤§ã€‚ä½†æ˜¯ï¼Œå®é™…ä¸ŠRDDå·²ç»è¢«å®è·µè¯æ˜å¯ä»¥å¾ˆå¥½åœ°åº”ç”¨äºè®¸å¤šå¹¶è¡Œè®¡ç®—åº”ç”¨ä¸­ï¼Œå¯ä»¥å…·å¤‡å¾ˆå¤šç°æœ‰è®¡ç®—æ¡†æ¶ï¼ˆæ¯”å¦‚MapReduceã€SQLã€Pregelç­‰ï¼‰çš„è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶ä¸”å¯ä»¥åº”ç”¨äºè¿™äº›æ¡†æ¶å¤„ç†ä¸äº†çš„äº¤äº’å¼æ•°æ®æŒ–æ˜åº”ç”¨ã€‚</p>

<p>Sparkç”¨Scalaè¯­è¨€å®ç°äº†RDDçš„APIï¼Œç¨‹åºå‘˜å¯ä»¥é€šè¿‡è°ƒç”¨APIå®ç°å¯¹RDDçš„å„ç§æ“ä½œã€‚RDDå…¸å‹çš„æ‰§è¡Œè¿‡ç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
  <li>RDDè¯»å…¥å¤–éƒ¨æ•°æ®æºï¼ˆæˆ–è€…å†…å­˜ä¸­çš„é›†åˆï¼‰è¿›è¡Œåˆ›å»ºï¼›</li>
  <li>RDDç»è¿‡ä¸€ç³»åˆ—çš„â€œè½¬æ¢â€æ“ä½œï¼Œæ¯ä¸€æ¬¡éƒ½ä¼šäº§ç”Ÿä¸åŒçš„RDDï¼Œä¾›ç»™ä¸‹ä¸€ä¸ªâ€œè½¬æ¢â€ä½¿ç”¨ï¼›</li>
  <li>æœ€åä¸€ä¸ªRDDç»â€œè¡ŒåŠ¨â€æ“ä½œè¿›è¡Œå¤„ç†ï¼Œå¹¶è¾“å‡ºåˆ°å¤–éƒ¨æ•°æ®æºï¼ˆæˆ–è€…å˜æˆScalaé›†åˆæˆ–æ ‡é‡ï¼‰ã€‚</li>
</ol>

<p>éœ€è¦è¯´æ˜çš„æ˜¯ï¼ŒRDDé‡‡ç”¨äº†æƒ°æ€§è°ƒç”¨ï¼Œå³åœ¨RDDçš„æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼ŒçœŸæ­£çš„è®¡ç®—å‘ç”Ÿåœ¨RDDçš„â€œè¡ŒåŠ¨â€æ“ä½œï¼Œå¯¹äºâ€œè¡ŒåŠ¨â€ä¹‹å‰çš„æ‰€æœ‰â€œè½¬æ¢â€æ“ä½œï¼ŒSparkåªæ˜¯è®°å½•ä¸‹â€œè½¬æ¢â€æ“ä½œåº”ç”¨çš„ä¸€äº›åŸºç¡€æ•°æ®é›†ä»¥åŠRDDç”Ÿæˆçš„è½¨è¿¹ï¼Œå³ç›¸äº’ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œè€Œä¸ä¼šè§¦å‘çœŸæ­£çš„è®¡ç®—ã€‚</p>

<h2 id="å››-ä½¿ç”¨intellij-ideaç¼–å†™sparkåº”ç”¨ç¨‹åºscalamaven">å››ã€ ä½¿ç”¨IntelliJ IDEAç¼–å†™Sparkåº”ç”¨ç¨‹åºï¼ˆScala+Mavenï¼‰</h2>
<p>ä½¿ç”¨IntelliJ IDEAç¼–å†™scalaç¨‹åºéœ€è¦å®‰è£…scalaæ’ä»¶å’Œsdkï¼Œå®‰è£…æ–¹æ³•å¯ä»¥å‚è€ƒå¦ä¸€ç¯‡åšæ–‡:Scalaé€Ÿå­¦ã€‚</p>

<p>åœ¨æœ‰äº†scalaæ’ä»¶å’Œsdkä¹‹åï¼Œä¾¿å¯ä»¥æ–°å»ºä¸€ä¸ªmavené¡¹ç›®ï¼Œpomæ–‡ä»¶ä¸­å¯ä»¥ä½¿ç”¨ä¾èµ–:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;properties&gt;
    &lt;spark.version&gt;2.1.0&lt;/spark.version&gt;
    &lt;scala.version&gt;2.11&lt;/scala.version&gt;
&lt;/properties&gt;


&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-core_${scala.version}&lt;/artifactId&gt;
        &lt;version&gt;${spark.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-streaming_${scala.version}&lt;/artifactId&gt;
        &lt;version&gt;${spark.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-sql_${scala.version}&lt;/artifactId&gt;
        &lt;version&gt;${spark.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-hive_${scala.version}&lt;/artifactId&gt;
        &lt;version&gt;${spark.version}&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
        &lt;artifactId&gt;spark-mllib_${scala.version}&lt;/artifactId&gt;
        &lt;version&gt;${spark.version}&lt;/version&gt;
    &lt;/dependency&gt;

&lt;/dependencies&gt;
</code></pre></div></div>

<p>å¯¼å…¥ä¾èµ–åå¯ä»¥æ–°å»ºä¸€ä¸ªæµ‹è¯•ç±»WordCount.scalaæµ‹è¯•èƒ½å¦æ­£å¸¸è°ƒè¯•,æµ‹è¯•ç±»ä»£ç å¦‚ä¸‹:
import org.apache.spark.sql.SparkSession</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>object WordCount
{
	def main(args: Array[String]): Unit =
	{
		val spark = SparkSession.builder()
			.master("local") //æœ¬åœ°æ¨¡å¼
			.appName("WordCount")
			.getOrCreate()
		
		val result = spark.read.textFile("file:///D:/Test/test.txt") //è¯»å–çš„æ–‡ä»¶ï¼Œæ”¯æŒæ­£åˆ™å¦‚test.*
			.rdd
			.flatMap(line =&gt; line.split(" "))
			.map((_, 1))
			.reduceByKey(_+_)
			.collect()
		println(result.toBuffer)

	}
}
</code></pre></div></div>

<p>è¿›è¡Œdebugï¼Œä¼šå¯åŠ¨å•æœºæ¨¡å¼çš„sparkï¼Œè¿è¡Œç»“æœå¦‚ä¸‹ï¼š</p>

<p><img src="/images/shenbin3/spark/result.png" alt="" /></p>

<p>åˆ°æ­¤å°±èƒ½è¿›è¡Œsparkç¨‹åºçš„å¼€å‘äº†ã€‚</p>

<h2 id="äº”sparkç¼–ç¨‹åŸºç¡€">äº”ã€Sparkç¼–ç¨‹åŸºç¡€</h2>
<h4 id="1è¯»å†™æ–‡ä»¶">1.è¯»å†™æ–‡ä»¶</h4>
<p>é™¤äº†å¯ä»¥å¯¹æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¿›è¡Œè¯»å†™ä»¥å¤–ï¼ŒSparkè¿˜æ”¯æŒå¾ˆå¤šå…¶ä»–å¸¸è§çš„æ–‡ä»¶æ ¼å¼ï¼ˆå¦‚æ–‡æœ¬æ–‡ä»¶ã€JSONã€SequenceFileç­‰ï¼‰å’Œæ–‡ä»¶ç³»ç»Ÿï¼ˆå¦‚HDFSã€Amazon S3ç­‰ï¼‰å’Œæ•°æ®åº“ï¼ˆå¦‚MySQLã€HBaseã€Hiveç­‰ï¼‰ã€‚æ•°æ®åº“çš„è¯»å†™å°†åœ¨Spark SQLéƒ¨åˆ†ä»‹ç»ï¼Œè¿™é‡Œåªä»‹ç»hdfsæ–‡ä»¶ç³»ç»Ÿçš„è¯»å†™å’Œä¸åŒæ–‡ä»¶æ ¼å¼çš„è¯»å†™ã€‚</p>

<p>æœ¬åœ°æ–‡æœ¬æ–‡ä»¶å¯ä»¥ä½¿ç”¨textFile()å‡½æ•°è¿›è¡Œè¯»å–ï¼Œç”¨æ³•å¦‚ä¸‹:
        val spark = SparkSession.builder()
            .master(â€œlocalâ€) //æœ¬åœ°æ¨¡å¼
            .appName(â€œWordCountâ€)
            .getOrCreate()</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val result = spark.read.textFile("file:///D:/Test/test.txt") //è¯»å–çš„æ–‡ä»¶ï¼Œæ”¯æŒæ­£åˆ™å¦‚test.*
        .rdd
        .flatMap(line =&gt; line.split(" "))

    result.saveAsTextFile("file:///D:/Test/out.txt")
</code></pre></div></div>

<p>test.txtæ–‡ä»¶å†…å®¹å¦‚ä¸‹:</p>

<p><img src="/images/shenbin3/spark/test.png" alt="" /></p>

<p>è¿è¡Œä»¥ä¸Šä»£ç ä¹‹åä¼šåœ¨Dç›˜Testæ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆä¸€ä¸ªout.txt æ–‡ä»¶å¤¹ï¼Œå†…å®¹å¦‚ä¸‹:</p>

<p><img src="/images/shenbin3/spark/out_dir.png" alt="" /></p>

<p>æŸ¥çœ‹part-00000æ–‡ä»¶ï¼Œå†…å®¹å¦‚ä¸‹:</p>

<p><img src="/images/shenbin3/spark/part000000.png" alt="" /></p>

<p>å¯ä»¥å‘ç°part-00000æ–‡ä»¶ä¸­çš„å†…å®¹ä¸ºç¨‹åºçš„é¢„æœŸç»“æœï¼Œé‚£å¦‚æœæƒ³è¦å†æ¬¡æŠŠæ•°æ®åŠ è½½åˆ°RDDæ—¶å€™è¦ä½¿ç”¨è¯¥æ–‡ä»¶å—ï¼Ÿå…¶å®ä¸éœ€è¦ï¼Œåªè¦ä½¿ç”¨spark.read.textFile(â€œD:\Test\out.txtâ€)åˆšæ‰ç”Ÿæˆçš„æ–‡ä»¶å¤¹å³å¯ã€‚</p>

<p>åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»ŸHDFSæ•°æ®è¯»å–å’Œæœ¬åœ°æ–‡ä»¶ç›¸åŒåªéœ€æŒ‡å®šhdfsåœ°å€ï¼Œä»£ç å¦‚ä¸‹:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val spark = SparkSession.builder()
        .master("local") //æœ¬åœ°æ¨¡å¼
        .appName("WordCount")
        .getOrCreate()

    val result = spark.read.textFile("hdfs://localhost:9000/user/hadoop/word.txt")
</code></pre></div></div>

<h2 id="å…­sparksql">å…­ã€SparkSQL</h2>
<h4 id="61-sparksql-ç®€ä»‹">6.1 SparkSQL ç®€ä»‹</h4>
<p>Spark SQLæ˜¯Sparkç”Ÿæ€ç³»ç»Ÿä¸­éå¸¸é‡è¦çš„ç»„ä»¶ï¼Œå…¶å‰èº«ä¸ºSharkã€‚Sharkæ˜¯Sparkä¸Šçš„æ•°æ®ä»“åº“ï¼Œæœ€åˆè®¾è®¡æˆä¸Hiveå…¼å®¹ï¼Œä½†æ˜¯è¯¥é¡¹ç›®äº2014å¹´å¼€å§‹åœæ­¢å¼€å‘ï¼Œè½¬å‘Spark SQLã€‚Spark SQLå…¨é¢ç»§æ‰¿äº†Sharkï¼Œå¹¶è¿›è¡Œäº†ä¼˜åŒ–ã€‚</p>

<p>Spark SQLå¢åŠ äº†SchemaRDDï¼ˆå³å¸¦æœ‰Schemaä¿¡æ¯çš„RDDï¼‰ï¼Œä½¿ç”¨æˆ·å¯ä»¥åœ¨Spark SQLä¸­æ‰§è¡ŒSQLè¯­å¥ï¼Œæ•°æ®æ—¢å¯ä»¥æ¥è‡ªRDDï¼Œä¹Ÿå¯ä»¥æ¥è‡ªHiveã€HDFSã€Cassandraç­‰å¤–éƒ¨æ•°æ®æºï¼Œè¿˜å¯ä»¥æ˜¯JSONæ ¼å¼çš„æ•°æ®ã€‚ä»Spark1.2 å‡çº§åˆ°Spark1.3ä»¥åï¼ŒSpark SQLä¸­çš„SchemaRDDå˜ä¸ºäº†DataFrameï¼ŒDataFrameç›¸å¯¹äºSchemaRDDæœ‰äº†è¾ƒå¤§æ”¹å˜,åŒæ—¶æä¾›äº†æ›´å¤šå¥½ç”¨ä¸”æ–¹ä¾¿çš„APIã€‚</p>

<p>Spark SQLå¯ä»¥å¾ˆå¥½åœ°æ”¯æŒSQLæŸ¥è¯¢ï¼Œå¯ä»¥ç¼–å†™Sparkåº”ç”¨ç¨‹åºä½¿ç”¨SQLè¯­å¥è¿›è¡Œæ•°æ®æŸ¥è¯¢ï¼Œå¦ä¸€æ–¹é¢ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ ‡å‡†çš„æ•°æ®åº“è¿æ¥å™¨ï¼ˆæ¯”å¦‚JDBCæˆ–ODBCï¼‰è¿æ¥Sparkè¿›è¡ŒSQLæŸ¥è¯¢ã€‚</p>
<h4 id="62-sparksqlä½¿ç”¨">6.2 SparkSQLä½¿ç”¨</h4>
<p>SparkSQLå¯ä»¥æŠŠDataFrameå½“ä½œä¸´æ—¶è¡¨ï¼Œåªéœ€ä½¿ç”¨sqlè¯­å¥ä¾¿å¯å®Œæˆå¯¹æ•°æ®çš„æ“ä½œã€‚</p>

<p>è¦ä½¿ç”¨DataFrameéœ€è¦å¼•å…¥éšå¼è½¬æ¢:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    val spark = SparkSession.builder()
        .master("local") //æœ¬åœ°æ¨¡å¼
        .appName("WordCount")
        .getOrCreate()
    import spark.implicits._//éšå¼è½¬æ¢

    val result = spark.read.textFile("hdfs://localhost:9000/user/hadoop/word.txt") //è¯»å–çš„æ–‡ä»¶ï¼Œæ”¯æŒæ­£åˆ™å¦‚test.*
        .rdd
        .flatMap(line =&gt; line.split(" "))
        .toDF()
    
    result.createOrReplaceTempView("tf_f_word")
    spark.sql("select * from tf_f_word").show()
</code></pre></div></div>

<p>å¼•å…¥éšå¼è½¬æ¢åä¾¿å¯å°†RDDè½¬æ¢æˆDataFrameï¼Œè°ƒç”¨createOrReplaceTempView æ–¹æ³•å¯å°†æ•°æ®ä½œä¸ºä¸´æ—¶è¡¨ä½¿ç”¨sqlè¯­å¥è¿›è¡Œæ“ä½œã€‚ä»¥ä¸Šä»£ç ç»“æœå¦‚ä¸‹:</p>

<p><img src="/images/shenbin3/spark/table_result.png" alt="" /></p>

<p>ä¸Šé¢æŠŠæ¯è¡Œæ•°æ®éƒ½ä¸ºstringï¼Œç›´æ¥è½¬æ¢ä¸ºDataFrameæ˜¯æ²¡æœ‰å®šä¹‰å­—æ®µåçš„ï¼Œå½“ç„¶ä½ å¯ä»¥ä¸ºä»–å®šä¹‰å­—æ®µåï¼Œä¸è¿‡è¿˜æœ‰æ›´ç®€å•çš„æ–¹æ³•ï¼ŒæŠŠæ•°æ®mapæˆcase classå³å¯ï¼Œä»£ç å¦‚ä¸‹:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	case class Word(word:String,count:Int)
	
	def main(args: Array[String]): Unit =
	{
		val spark = SparkSession.builder()
			.master("local") //æœ¬åœ°æ¨¡å¼
			.appName("WordCount")
			.getOrCreate()
		import spark.implicits._//éšå¼è½¬æ¢
	
		val result = spark.read.textFile("file:///D:/Test/test.txt") //è¯»å–çš„æ–‡ä»¶ï¼Œæ”¯æŒæ­£åˆ™å¦‚test.*
			.rdd
			.flatMap(line =&gt; line.split(" "))
			.map(word =&gt; Word(word,1))
			.toDF()
	
		result.createOrReplaceTempView("tf_f_word")
	
		spark.sql("select * from tf_f_word").show()
		spark.sql("select word,sum(count) as wordCounts from tf_f_word group by word").show()
	
	}
</code></pre></div></div>

<p>ä»£ç ç»“æœå¦‚ä¸‹ï¼š</p>

<p>tf_f_word çš„å†…å®¹ï¼š
<img src="/images/shenbin3/spark/word_table.png" alt="" /></p>

<p>è®¡æ•°ç»“æœ:
<img src="/images/shenbin3/spark/word_counts.png" alt="" /></p>

<h4 id="63-è¿æ¥æ•°æ®åº“">6.3 è¿æ¥æ•°æ®åº“</h4>
<p>åœ¨è®¡ç®—å®Œåè®¸å¤šæ—¶å€™éœ€è¦æŠŠè®¡ç®—ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“ï¼ŒDataFrameå¯ä»¥éå¸¸æ–¹ä¾¿çš„å­˜å…¥æ•°æ®åº“,ä»£ç å¦‚ä¸‹:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import java.util.Properties
import org.apache.spark.sql.{SaveMode, SparkSession}

object WordCount
{
	case class Word(word:String,count:Int)

	def main(args: Array[String]): Unit =
	{
		val spark = SparkSession.builder()
			.master("local") //æœ¬åœ°æ¨¡å¼
			.appName("WordCount")
			.getOrCreate()
		import spark.implicits._//éšå¼è½¬æ¢

		val result = spark.read.textFile("file:///D:/Test/test.txt") //è¯»å–çš„æ–‡ä»¶ï¼Œæ”¯æŒæ­£åˆ™å¦‚test.*
			.rdd
			.flatMap(line =&gt; line.split(" "))
			.map(word =&gt; Word(word,1))
			.toDF()

		result.createOrReplaceTempView("tf_f_word")

		spark.sql("select * from tf_f_word").show()
		val wordCounts = spark.sql("select word,sum(count) as count from tf_f_word group by word")

		val properties = new Properties()
		properties.put("user", "root")//æ•°æ®åº“è¿æ¥ç”¨æˆ·åå¯†ç 
		properties.put("password", "root")
		Class.forName("com.mysql.jdbc.Driver").newInstance()//åŠ è½½jdbc
		wordCounts.write.mode(SaveMode.Append).jdbc("jdbc:mysql://localhost:3306/db","tf_f_word_counts",properties)//å†™å…¥æ•°æ®åº“

	}
}
</code></pre></div></div>

<p>è¿è¡Œä»¥ä¸Šä»£ç ï¼Œä¼šå°†å¤„ç†ç»“æœæ’å…¥æœ¬åœ°æ•°æ®åº“dbåº“ä¸­çš„tf_f_word_countsè¡¨ä¸­,è¡¨ä¸­æ•°æ®å¦‚ä¸‹:</p>

<p><img src="/images/shenbin3/spark/db_result.png" alt="" /></p>

<p>æœ‰æ—¶æˆ‘ä»¬ä¹Ÿéœ€è¦ä»æ•°æ®åº“ä¸­è¯»å–æ•°æ®,sprkSQLå¯ä»¥ç›´æ¥æŠŠè¡¨è¯»å–æˆDataFrame,ä»£ç å¦‚ä¸‹:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	val spark = SparkSession.builder()
		.master("local") //æœ¬åœ°æ¨¡å¼
		.appName("WordCount")
		.getOrCreate()
	import spark.implicits._//éšå¼è½¬æ¢
	
	val properties = new Properties()
	properties.put("user", "root")//æ•°æ®åº“è¿æ¥ç”¨æˆ·åå¯†ç 
	properties.put("password", "root")
	Class.forName("com.mysql.jdbc.Driver").newInstance()//åŠ è½½jdbc
	val table = spark.read.jdbc("jdbc:mysql://localhost:3306/db","tf_f_word_counts",properties)//æŸ¥è¯¢æ•°æ®åº“
    table.show()
</code></pre></div></div>

<p>ä»¥ä¸Šä»£ç ä¾¿èƒ½è¯»å–åˆšåˆšå­˜å…¥æ•°æ®åº“çš„tf_f_word_countsè¡¨ï¼Œè¿è¡Œç»“æœå¦‚ä¸‹:</p>

<p><img src="/images/shenbin3/spark/from_db.png" alt="" /></p>

:ET